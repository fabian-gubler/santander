{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lGpKq5vD-f3W"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"0vN_qRZ1OcUm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671805405068,"user_tz":-60,"elapsed":16825,"user":{"displayName":"Sven Schnydrig","userId":"07537939478620197257"}},"outputId":"dbc0dfde-2625-4c07-82ce-511b5391b601"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"OMH8R-L-RF88","executionInfo":{"status":"ok","timestamp":1671806495708,"user_tz":-60,"elapsed":17061,"user":{"displayName":"Sven Schnydrig","userId":"07537939478620197257"}},"outputId":"82caf2e9-885b-42be-cdd5-838fb4736487","colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","import pandas as pd\n","train=pd.read_csv('/content/drive/MyDrive/Data Science Project - Team D/data/raw-data/train.csv')\n","\n","train.describe().apply(lambda s: s.apply('{0:.5f}'.format))\n","\n","test=pd.read_csv('/content/drive/MyDrive/Data Science Project - Team D/data/raw-data/test.csv')\n","test.describe().apply(lambda s: s.apply('{0:.5f}'.format))"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              var_0         var_1         var_2         var_3         var_4  \\\n","count  200000.00000  200000.00000  200000.00000  200000.00000  200000.00000   \n","mean       10.65874      -1.62424      10.70745       6.78821      11.07640   \n","std         3.03672       4.04051       2.63389       2.05272       1.61646   \n","min         0.18870     -15.04340       2.35520      -0.02240       5.48440   \n","25%         8.44298      -4.70012       8.73560       5.23050       9.89108   \n","50%        10.51380      -1.59050      10.56070       6.82235      11.09975   \n","75%        12.73960       1.34340      12.49503       8.32760      12.25340   \n","max        22.32340       9.38510      18.71410      13.14200      16.03710   \n","\n","              var_5         var_6         var_7         var_8         var_9  \\\n","count  200000.00000  200000.00000  200000.00000  200000.00000  200000.00000   \n","mean       -5.05056       5.41516      16.52914       0.27713       7.56941   \n","std         7.86929       0.86469       3.42448       3.33337       1.23187   \n","min       -27.76700       2.21640       5.71370      -9.95600       4.24330   \n","25%       -11.20140       4.77260      13.93390      -2.30390       6.62380   \n","50%        -4.83410       5.39160      16.42270       0.37200       7.63200   \n","75%         0.94257       6.00580      19.09455       2.93003       8.58482   \n","max        17.25370       8.30250      28.29280       9.66550      11.00360   \n","\n","       ...       var_190       var_191       var_192       var_193  \\\n","count  ...  200000.00000  200000.00000  200000.00000  200000.00000   \n","mean   ...       3.18977       7.45827       1.92594       3.32202   \n","std    ...       4.55124       3.02519       1.47997       3.99560   \n","min    ...     -14.09330      -2.40700      -3.34090     -11.41310   \n","25%    ...      -0.09500       5.16650       0.88298       0.58760   \n","50%    ...       3.16240       7.37900       1.89260       3.42850   \n","75%    ...       6.33648       9.53110       2.95600       6.17420   \n","max    ...      20.35900      16.71650       8.00500      17.63260   \n","\n","            var_194       var_195       var_196       var_197       var_198  \\\n","count  200000.00000  200000.00000  200000.00000  200000.00000  200000.00000   \n","mean       17.99697      -0.13366       2.29090       8.91243      15.86918   \n","std         3.14065       1.42968       5.44635       0.92090       3.00872   \n","min         9.38280      -4.91190     -13.94420       6.16960       6.58400   \n","25%        15.63478      -1.16070      -1.94860       8.26008      13.84727   \n","50%        17.97760      -0.16200       2.40360       8.89280      15.94340   \n","75%        20.39173       0.83790       6.51980       9.59590      18.04520   \n","max        27.94780       4.54540      15.92070      12.27580      26.53840   \n","\n","            var_199  \n","count  200000.00000  \n","mean       -3.24634  \n","std        10.39859  \n","min       -39.45780  \n","25%       -11.12400  \n","50%        -2.72595  \n","75%         4.93540  \n","max        27.90740  \n","\n","[8 rows x 200 columns]"],"text/html":["\n","  <div id=\"df-bd7f062f-db03-408d-8349-21b046b6ce46\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>var_0</th>\n","      <th>var_1</th>\n","      <th>var_2</th>\n","      <th>var_3</th>\n","      <th>var_4</th>\n","      <th>var_5</th>\n","      <th>var_6</th>\n","      <th>var_7</th>\n","      <th>var_8</th>\n","      <th>var_9</th>\n","      <th>...</th>\n","      <th>var_190</th>\n","      <th>var_191</th>\n","      <th>var_192</th>\n","      <th>var_193</th>\n","      <th>var_194</th>\n","      <th>var_195</th>\n","      <th>var_196</th>\n","      <th>var_197</th>\n","      <th>var_198</th>\n","      <th>var_199</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>...</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","      <td>200000.00000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>10.65874</td>\n","      <td>-1.62424</td>\n","      <td>10.70745</td>\n","      <td>6.78821</td>\n","      <td>11.07640</td>\n","      <td>-5.05056</td>\n","      <td>5.41516</td>\n","      <td>16.52914</td>\n","      <td>0.27713</td>\n","      <td>7.56941</td>\n","      <td>...</td>\n","      <td>3.18977</td>\n","      <td>7.45827</td>\n","      <td>1.92594</td>\n","      <td>3.32202</td>\n","      <td>17.99697</td>\n","      <td>-0.13366</td>\n","      <td>2.29090</td>\n","      <td>8.91243</td>\n","      <td>15.86918</td>\n","      <td>-3.24634</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>3.03672</td>\n","      <td>4.04051</td>\n","      <td>2.63389</td>\n","      <td>2.05272</td>\n","      <td>1.61646</td>\n","      <td>7.86929</td>\n","      <td>0.86469</td>\n","      <td>3.42448</td>\n","      <td>3.33337</td>\n","      <td>1.23187</td>\n","      <td>...</td>\n","      <td>4.55124</td>\n","      <td>3.02519</td>\n","      <td>1.47997</td>\n","      <td>3.99560</td>\n","      <td>3.14065</td>\n","      <td>1.42968</td>\n","      <td>5.44635</td>\n","      <td>0.92090</td>\n","      <td>3.00872</td>\n","      <td>10.39859</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.18870</td>\n","      <td>-15.04340</td>\n","      <td>2.35520</td>\n","      <td>-0.02240</td>\n","      <td>5.48440</td>\n","      <td>-27.76700</td>\n","      <td>2.21640</td>\n","      <td>5.71370</td>\n","      <td>-9.95600</td>\n","      <td>4.24330</td>\n","      <td>...</td>\n","      <td>-14.09330</td>\n","      <td>-2.40700</td>\n","      <td>-3.34090</td>\n","      <td>-11.41310</td>\n","      <td>9.38280</td>\n","      <td>-4.91190</td>\n","      <td>-13.94420</td>\n","      <td>6.16960</td>\n","      <td>6.58400</td>\n","      <td>-39.45780</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>8.44298</td>\n","      <td>-4.70012</td>\n","      <td>8.73560</td>\n","      <td>5.23050</td>\n","      <td>9.89108</td>\n","      <td>-11.20140</td>\n","      <td>4.77260</td>\n","      <td>13.93390</td>\n","      <td>-2.30390</td>\n","      <td>6.62380</td>\n","      <td>...</td>\n","      <td>-0.09500</td>\n","      <td>5.16650</td>\n","      <td>0.88298</td>\n","      <td>0.58760</td>\n","      <td>15.63478</td>\n","      <td>-1.16070</td>\n","      <td>-1.94860</td>\n","      <td>8.26008</td>\n","      <td>13.84727</td>\n","      <td>-11.12400</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>10.51380</td>\n","      <td>-1.59050</td>\n","      <td>10.56070</td>\n","      <td>6.82235</td>\n","      <td>11.09975</td>\n","      <td>-4.83410</td>\n","      <td>5.39160</td>\n","      <td>16.42270</td>\n","      <td>0.37200</td>\n","      <td>7.63200</td>\n","      <td>...</td>\n","      <td>3.16240</td>\n","      <td>7.37900</td>\n","      <td>1.89260</td>\n","      <td>3.42850</td>\n","      <td>17.97760</td>\n","      <td>-0.16200</td>\n","      <td>2.40360</td>\n","      <td>8.89280</td>\n","      <td>15.94340</td>\n","      <td>-2.72595</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>12.73960</td>\n","      <td>1.34340</td>\n","      <td>12.49503</td>\n","      <td>8.32760</td>\n","      <td>12.25340</td>\n","      <td>0.94257</td>\n","      <td>6.00580</td>\n","      <td>19.09455</td>\n","      <td>2.93003</td>\n","      <td>8.58482</td>\n","      <td>...</td>\n","      <td>6.33648</td>\n","      <td>9.53110</td>\n","      <td>2.95600</td>\n","      <td>6.17420</td>\n","      <td>20.39173</td>\n","      <td>0.83790</td>\n","      <td>6.51980</td>\n","      <td>9.59590</td>\n","      <td>18.04520</td>\n","      <td>4.93540</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>22.32340</td>\n","      <td>9.38510</td>\n","      <td>18.71410</td>\n","      <td>13.14200</td>\n","      <td>16.03710</td>\n","      <td>17.25370</td>\n","      <td>8.30250</td>\n","      <td>28.29280</td>\n","      <td>9.66550</td>\n","      <td>11.00360</td>\n","      <td>...</td>\n","      <td>20.35900</td>\n","      <td>16.71650</td>\n","      <td>8.00500</td>\n","      <td>17.63260</td>\n","      <td>27.94780</td>\n","      <td>4.54540</td>\n","      <td>15.92070</td>\n","      <td>12.27580</td>\n","      <td>26.53840</td>\n","      <td>27.90740</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 200 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd7f062f-db03-408d-8349-21b046b6ce46')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bd7f062f-db03-408d-8349-21b046b6ce46 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bd7f062f-db03-408d-8349-21b046b6ce46');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"yhW2rSwI-nyL"},"source":["# Split and normalize data"]},{"cell_type":"code","source":["#shuffle data\n","train = train.sample(frac=1)\n","\n","X = train.drop(['target', 'ID_code'], axis=1)\n","y=train[['target']]\n","\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler() \n","X = scaler.fit_transform(X) \n","\n","from sklearn.model_selection import train_test_split\n","# split into 80% train, 10% validation, 10% test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n","X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=1) # 0.2 x 0.5 = 0.1"],"metadata":{"id":"zb2I6IjuhKSo","executionInfo":{"status":"ok","timestamp":1671805448802,"user_tz":-60,"elapsed":2774,"user":{"displayName":"Sven Schnydrig","userId":"07537939478620197257"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_btigeAV_4PO"},"source":["# Train and evaluate model"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras"],"metadata":{"id":"82FFX6BXZQF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wav4UgmZHdrW","outputId":"c4a12ae7-af01-46d3-ddc9-760e77905e87","executionInfo":{"status":"ok","timestamp":1671806914698,"user_tz":-60,"elapsed":86883,"user":{"displayName":"Sven Schnydrig","userId":"07537939478620197257"}}},"source":["l2_reg = keras.regularizers.l2(0.1)\n","\n","input_ = keras.layers.Input(shape=[200])\n","hidden1 = keras.layers.Dense(200, activation=\"relu\", kernel_constraint=keras.constraints.max_norm(1.0), kernel_regularizer=l2_reg)(input_)\n","hidden1 = tf.keras.layers.Dropout(0.6)(hidden1)\n","hidden2 = keras.layers.Dense(200, activation=\"relu\", kernel_constraint=keras.constraints.max_norm(1.0), kernel_regularizer=l2_reg)(hidden1)\n","hidden2 = tf.keras.layers.Dropout(0.6)(hidden2)\n","hidden3 = keras.layers.Dense(200, activation=\"relu\", kernel_constraint=keras.constraints.max_norm(1.0), kernel_regularizer=l2_reg)(hidden2)\n","hidden3 = tf.keras.layers.Dropout(0.6)(hidden3)\n","concat = keras.layers.Concatenate()([input_, hidden3])\n","output = keras.layers.Dense(1, activation=\"sigmoid\")(concat)\n","model = keras.Model(inputs=[input_], outputs=[output])\n","\n","#checkpoint_cb = keras.callbacks.ModelCheckpoint(\"m1.h5\", save_best_only=True)\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n","tensorboard_cb = keras.callbacks.TensorBoard('/content/drive/MyDrive/Data Science Project - Team D/data/logs')\n","\n","METRICS = [\n","      keras.metrics.TruePositives(name='tp'),\n","      keras.metrics.FalsePositives(name='fp'),\n","      keras.metrics.TrueNegatives(name='tn'),\n","      keras.metrics.FalseNegatives(name='fn'), \n","      keras.metrics.BinaryAccuracy(name='accuracy'),\n","      keras.metrics.Precision(name='precision'),\n","      keras.metrics.Recall(name='recall'),\n","      keras.metrics.AUC(name='auc'),\n","      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n","]\n","\n","\n","model.compile(loss=\"BinaryCrossentropy\", optimizer=\"adam\", metrics=METRICS)\n","history = model.fit(X_train, y_train, epochs=100, batch_size=1000, validation_data=(X_valid, y_valid), callbacks=[early_stopping_cb])"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","160/160 [==============================] - 4s 14ms/step - loss: 13.2555 - tp: 1330.0000 - fp: 4177.0000 - tn: 139701.0000 - fn: 14792.0000 - accuracy: 0.8814 - precision: 0.2415 - recall: 0.0825 - auc: 0.6892 - prc: 0.1863 - val_loss: 0.4923 - val_tp: 112.0000 - val_fp: 31.0000 - val_tn: 18001.0000 - val_fn: 1856.0000 - val_accuracy: 0.9057 - val_precision: 0.7832 - val_recall: 0.0569 - val_auc: 0.8337 - val_prc: 0.4342\n","Epoch 2/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2820 - tp: 2128.0000 - fp: 686.0000 - tn: 143192.0000 - fn: 13994.0000 - accuracy: 0.9082 - precision: 0.7562 - recall: 0.1320 - auc: 0.8386 - prc: 0.4589 - val_loss: 0.2331 - val_tp: 363.0000 - val_fp: 109.0000 - val_tn: 17923.0000 - val_fn: 1605.0000 - val_accuracy: 0.9143 - val_precision: 0.7691 - val_recall: 0.1845 - val_auc: 0.8595 - val_prc: 0.4966\n","Epoch 3/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2388 - tp: 3443.0000 - fp: 1443.0000 - tn: 142435.0000 - fn: 12679.0000 - accuracy: 0.9117 - precision: 0.7047 - recall: 0.2136 - auc: 0.8520 - prc: 0.4856 - val_loss: 0.2283 - val_tp: 477.0000 - val_fp: 173.0000 - val_tn: 17859.0000 - val_fn: 1491.0000 - val_accuracy: 0.9168 - val_precision: 0.7338 - val_recall: 0.2424 - val_auc: 0.8631 - val_prc: 0.5069\n","Epoch 4/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2366 - tp: 3970.0000 - fp: 1825.0000 - tn: 142053.0000 - fn: 12152.0000 - accuracy: 0.9126 - precision: 0.6851 - recall: 0.2462 - auc: 0.8538 - prc: 0.4924 - val_loss: 0.2271 - val_tp: 508.0000 - val_fp: 186.0000 - val_tn: 17846.0000 - val_fn: 1460.0000 - val_accuracy: 0.9177 - val_precision: 0.7320 - val_recall: 0.2581 - val_auc: 0.8635 - val_prc: 0.5096\n","Epoch 5/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2363 - tp: 4188.0000 - fp: 1987.0000 - tn: 141891.0000 - fn: 11934.0000 - accuracy: 0.9130 - precision: 0.6782 - recall: 0.2598 - auc: 0.8541 - prc: 0.4945 - val_loss: 0.2269 - val_tp: 549.0000 - val_fp: 232.0000 - val_tn: 17800.0000 - val_fn: 1419.0000 - val_accuracy: 0.9175 - val_precision: 0.7029 - val_recall: 0.2790 - val_auc: 0.8638 - val_prc: 0.5104\n","Epoch 6/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2360 - tp: 4270.0000 - fp: 2154.0000 - tn: 141724.0000 - fn: 11852.0000 - accuracy: 0.9125 - precision: 0.6647 - recall: 0.2649 - auc: 0.8545 - prc: 0.4953 - val_loss: 0.2267 - val_tp: 528.0000 - val_fp: 207.0000 - val_tn: 17825.0000 - val_fn: 1440.0000 - val_accuracy: 0.9176 - val_precision: 0.7184 - val_recall: 0.2683 - val_auc: 0.8638 - val_prc: 0.5109\n","Epoch 7/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2360 - tp: 4323.0000 - fp: 2189.0000 - tn: 141689.0000 - fn: 11799.0000 - accuracy: 0.9126 - precision: 0.6639 - recall: 0.2681 - auc: 0.8548 - prc: 0.4947 - val_loss: 0.2267 - val_tp: 538.0000 - val_fp: 217.0000 - val_tn: 17815.0000 - val_fn: 1430.0000 - val_accuracy: 0.9176 - val_precision: 0.7126 - val_recall: 0.2734 - val_auc: 0.8639 - val_prc: 0.5110\n","Epoch 8/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2365 - tp: 4411.0000 - fp: 2194.0000 - tn: 141684.0000 - fn: 11711.0000 - accuracy: 0.9131 - precision: 0.6678 - recall: 0.2736 - auc: 0.8537 - prc: 0.4937 - val_loss: 0.2266 - val_tp: 526.0000 - val_fp: 208.0000 - val_tn: 17824.0000 - val_fn: 1442.0000 - val_accuracy: 0.9175 - val_precision: 0.7166 - val_recall: 0.2673 - val_auc: 0.8640 - val_prc: 0.5116\n","Epoch 9/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2363 - tp: 4373.0000 - fp: 2192.0000 - tn: 141686.0000 - fn: 11749.0000 - accuracy: 0.9129 - precision: 0.6661 - recall: 0.2712 - auc: 0.8544 - prc: 0.4937 - val_loss: 0.2266 - val_tp: 541.0000 - val_fp: 223.0000 - val_tn: 17809.0000 - val_fn: 1427.0000 - val_accuracy: 0.9175 - val_precision: 0.7081 - val_recall: 0.2749 - val_auc: 0.8639 - val_prc: 0.5114\n","Epoch 10/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2360 - tp: 4326.0000 - fp: 2127.0000 - tn: 141751.0000 - fn: 11796.0000 - accuracy: 0.9130 - precision: 0.6704 - recall: 0.2683 - auc: 0.8549 - prc: 0.4940 - val_loss: 0.2268 - val_tp: 559.0000 - val_fp: 235.0000 - val_tn: 17797.0000 - val_fn: 1409.0000 - val_accuracy: 0.9178 - val_precision: 0.7040 - val_recall: 0.2840 - val_auc: 0.8641 - val_prc: 0.5112\n","Epoch 11/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2360 - tp: 4391.0000 - fp: 2187.0000 - tn: 141691.0000 - fn: 11731.0000 - accuracy: 0.9130 - precision: 0.6675 - recall: 0.2724 - auc: 0.8546 - prc: 0.4960 - val_loss: 0.2273 - val_tp: 605.0000 - val_fp: 269.0000 - val_tn: 17763.0000 - val_fn: 1363.0000 - val_accuracy: 0.9184 - val_precision: 0.6922 - val_recall: 0.3074 - val_auc: 0.8641 - val_prc: 0.5113\n","Epoch 12/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2358 - tp: 4362.0000 - fp: 2141.0000 - tn: 141737.0000 - fn: 11760.0000 - accuracy: 0.9131 - precision: 0.6708 - recall: 0.2706 - auc: 0.8549 - prc: 0.4955 - val_loss: 0.2270 - val_tp: 571.0000 - val_fp: 245.0000 - val_tn: 17787.0000 - val_fn: 1397.0000 - val_accuracy: 0.9179 - val_precision: 0.6998 - val_recall: 0.2901 - val_auc: 0.8638 - val_prc: 0.5105\n","Epoch 13/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2359 - tp: 4372.0000 - fp: 2222.0000 - tn: 141656.0000 - fn: 11750.0000 - accuracy: 0.9127 - precision: 0.6630 - recall: 0.2712 - auc: 0.8551 - prc: 0.4952 - val_loss: 0.2265 - val_tp: 541.0000 - val_fp: 224.0000 - val_tn: 17808.0000 - val_fn: 1427.0000 - val_accuracy: 0.9175 - val_precision: 0.7072 - val_recall: 0.2749 - val_auc: 0.8640 - val_prc: 0.5114\n","Epoch 14/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2355 - tp: 4392.0000 - fp: 2128.0000 - tn: 141750.0000 - fn: 11730.0000 - accuracy: 0.9134 - precision: 0.6736 - recall: 0.2724 - auc: 0.8553 - prc: 0.4971 - val_loss: 0.2265 - val_tp: 547.0000 - val_fp: 227.0000 - val_tn: 17805.0000 - val_fn: 1421.0000 - val_accuracy: 0.9176 - val_precision: 0.7067 - val_recall: 0.2779 - val_auc: 0.8643 - val_prc: 0.5115\n","Epoch 15/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2358 - tp: 4397.0000 - fp: 2139.0000 - tn: 141739.0000 - fn: 11725.0000 - accuracy: 0.9133 - precision: 0.6727 - recall: 0.2727 - auc: 0.8549 - prc: 0.4963 - val_loss: 0.2267 - val_tp: 543.0000 - val_fp: 224.0000 - val_tn: 17808.0000 - val_fn: 1425.0000 - val_accuracy: 0.9176 - val_precision: 0.7080 - val_recall: 0.2759 - val_auc: 0.8638 - val_prc: 0.5109\n","Epoch 16/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2356 - tp: 4388.0000 - fp: 2131.0000 - tn: 141747.0000 - fn: 11734.0000 - accuracy: 0.9133 - precision: 0.6731 - recall: 0.2722 - auc: 0.8553 - prc: 0.4970 - val_loss: 0.2267 - val_tp: 545.0000 - val_fp: 235.0000 - val_tn: 17797.0000 - val_fn: 1423.0000 - val_accuracy: 0.9171 - val_precision: 0.6987 - val_recall: 0.2769 - val_auc: 0.8639 - val_prc: 0.5107\n","Epoch 17/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2356 - tp: 4357.0000 - fp: 2151.0000 - tn: 141727.0000 - fn: 11765.0000 - accuracy: 0.9130 - precision: 0.6695 - recall: 0.2703 - auc: 0.8554 - prc: 0.4963 - val_loss: 0.2267 - val_tp: 549.0000 - val_fp: 240.0000 - val_tn: 17792.0000 - val_fn: 1419.0000 - val_accuracy: 0.9171 - val_precision: 0.6958 - val_recall: 0.2790 - val_auc: 0.8640 - val_prc: 0.5106\n","Epoch 18/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2356 - tp: 4350.0000 - fp: 2197.0000 - tn: 141681.0000 - fn: 11772.0000 - accuracy: 0.9127 - precision: 0.6644 - recall: 0.2698 - auc: 0.8552 - prc: 0.4966 - val_loss: 0.2268 - val_tp: 533.0000 - val_fp: 218.0000 - val_tn: 17814.0000 - val_fn: 1435.0000 - val_accuracy: 0.9173 - val_precision: 0.7097 - val_recall: 0.2708 - val_auc: 0.8640 - val_prc: 0.5106\n","Epoch 19/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2358 - tp: 4336.0000 - fp: 2125.0000 - tn: 141753.0000 - fn: 11786.0000 - accuracy: 0.9131 - precision: 0.6711 - recall: 0.2689 - auc: 0.8549 - prc: 0.4963 - val_loss: 0.2268 - val_tp: 549.0000 - val_fp: 234.0000 - val_tn: 17798.0000 - val_fn: 1419.0000 - val_accuracy: 0.9173 - val_precision: 0.7011 - val_recall: 0.2790 - val_auc: 0.8638 - val_prc: 0.5101\n","Epoch 20/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2355 - tp: 4338.0000 - fp: 2138.0000 - tn: 141740.0000 - fn: 11784.0000 - accuracy: 0.9130 - precision: 0.6699 - recall: 0.2691 - auc: 0.8555 - prc: 0.4968 - val_loss: 0.2266 - val_tp: 551.0000 - val_fp: 236.0000 - val_tn: 17796.0000 - val_fn: 1417.0000 - val_accuracy: 0.9173 - val_precision: 0.7001 - val_recall: 0.2800 - val_auc: 0.8640 - val_prc: 0.5110\n","Epoch 21/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2355 - tp: 4321.0000 - fp: 2156.0000 - tn: 141722.0000 - fn: 11801.0000 - accuracy: 0.9128 - precision: 0.6671 - recall: 0.2680 - auc: 0.8556 - prc: 0.4953 - val_loss: 0.2266 - val_tp: 544.0000 - val_fp: 230.0000 - val_tn: 17802.0000 - val_fn: 1424.0000 - val_accuracy: 0.9173 - val_precision: 0.7028 - val_recall: 0.2764 - val_auc: 0.8640 - val_prc: 0.5109\n","Epoch 22/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2351 - tp: 4379.0000 - fp: 2126.0000 - tn: 141752.0000 - fn: 11743.0000 - accuracy: 0.9133 - precision: 0.6732 - recall: 0.2716 - auc: 0.8557 - prc: 0.4991 - val_loss: 0.2266 - val_tp: 559.0000 - val_fp: 237.0000 - val_tn: 17795.0000 - val_fn: 1409.0000 - val_accuracy: 0.9177 - val_precision: 0.7023 - val_recall: 0.2840 - val_auc: 0.8638 - val_prc: 0.5109\n","Epoch 23/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2352 - tp: 4349.0000 - fp: 2119.0000 - tn: 141759.0000 - fn: 11773.0000 - accuracy: 0.9132 - precision: 0.6724 - recall: 0.2698 - auc: 0.8558 - prc: 0.4978 - val_loss: 0.2265 - val_tp: 531.0000 - val_fp: 213.0000 - val_tn: 17819.0000 - val_fn: 1437.0000 - val_accuracy: 0.9175 - val_precision: 0.7137 - val_recall: 0.2698 - val_auc: 0.8642 - val_prc: 0.5109\n","Epoch 24/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2353 - tp: 4313.0000 - fp: 2145.0000 - tn: 141733.0000 - fn: 11809.0000 - accuracy: 0.9128 - precision: 0.6679 - recall: 0.2675 - auc: 0.8555 - prc: 0.4976 - val_loss: 0.2265 - val_tp: 549.0000 - val_fp: 229.0000 - val_tn: 17803.0000 - val_fn: 1419.0000 - val_accuracy: 0.9176 - val_precision: 0.7057 - val_recall: 0.2790 - val_auc: 0.8639 - val_prc: 0.5113\n","Epoch 25/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2348 - tp: 4378.0000 - fp: 2116.0000 - tn: 141762.0000 - fn: 11744.0000 - accuracy: 0.9134 - precision: 0.6742 - recall: 0.2716 - auc: 0.8561 - prc: 0.4995 - val_loss: 0.2272 - val_tp: 611.0000 - val_fp: 288.0000 - val_tn: 17744.0000 - val_fn: 1357.0000 - val_accuracy: 0.9178 - val_precision: 0.6796 - val_recall: 0.3105 - val_auc: 0.8643 - val_prc: 0.5114\n","Epoch 26/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2348 - tp: 4381.0000 - fp: 2136.0000 - tn: 141742.0000 - fn: 11741.0000 - accuracy: 0.9133 - precision: 0.6722 - recall: 0.2717 - auc: 0.8563 - prc: 0.4994 - val_loss: 0.2265 - val_tp: 554.0000 - val_fp: 242.0000 - val_tn: 17790.0000 - val_fn: 1414.0000 - val_accuracy: 0.9172 - val_precision: 0.6960 - val_recall: 0.2815 - val_auc: 0.8642 - val_prc: 0.5112\n","Epoch 27/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2350 - tp: 4345.0000 - fp: 2154.0000 - tn: 141724.0000 - fn: 11777.0000 - accuracy: 0.9129 - precision: 0.6686 - recall: 0.2695 - auc: 0.8559 - prc: 0.4980 - val_loss: 0.2267 - val_tp: 567.0000 - val_fp: 247.0000 - val_tn: 17785.0000 - val_fn: 1401.0000 - val_accuracy: 0.9176 - val_precision: 0.6966 - val_recall: 0.2881 - val_auc: 0.8639 - val_prc: 0.5106\n","Epoch 28/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2349 - tp: 4384.0000 - fp: 2146.0000 - tn: 141732.0000 - fn: 11738.0000 - accuracy: 0.9132 - precision: 0.6714 - recall: 0.2719 - auc: 0.8562 - prc: 0.4988 - val_loss: 0.2265 - val_tp: 540.0000 - val_fp: 212.0000 - val_tn: 17820.0000 - val_fn: 1428.0000 - val_accuracy: 0.9180 - val_precision: 0.7181 - val_recall: 0.2744 - val_auc: 0.8637 - val_prc: 0.5112\n","Epoch 29/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2350 - tp: 4317.0000 - fp: 2152.0000 - tn: 141726.0000 - fn: 11805.0000 - accuracy: 0.9128 - precision: 0.6673 - recall: 0.2678 - auc: 0.8560 - prc: 0.4975 - val_loss: 0.2267 - val_tp: 569.0000 - val_fp: 245.0000 - val_tn: 17787.0000 - val_fn: 1399.0000 - val_accuracy: 0.9178 - val_precision: 0.6990 - val_recall: 0.2891 - val_auc: 0.8640 - val_prc: 0.5110\n","Epoch 30/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2346 - tp: 4300.0000 - fp: 2069.0000 - tn: 141809.0000 - fn: 11822.0000 - accuracy: 0.9132 - precision: 0.6751 - recall: 0.2667 - auc: 0.8564 - prc: 0.5001 - val_loss: 0.2265 - val_tp: 535.0000 - val_fp: 223.0000 - val_tn: 17809.0000 - val_fn: 1433.0000 - val_accuracy: 0.9172 - val_precision: 0.7058 - val_recall: 0.2718 - val_auc: 0.8641 - val_prc: 0.5111\n","Epoch 31/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2348 - tp: 4405.0000 - fp: 2166.0000 - tn: 141712.0000 - fn: 11717.0000 - accuracy: 0.9132 - precision: 0.6704 - recall: 0.2732 - auc: 0.8564 - prc: 0.4978 - val_loss: 0.2264 - val_tp: 551.0000 - val_fp: 226.0000 - val_tn: 17806.0000 - val_fn: 1417.0000 - val_accuracy: 0.9179 - val_precision: 0.7091 - val_recall: 0.2800 - val_auc: 0.8640 - val_prc: 0.5112\n","Epoch 32/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2347 - tp: 4339.0000 - fp: 2127.0000 - tn: 141751.0000 - fn: 11783.0000 - accuracy: 0.9131 - precision: 0.6710 - recall: 0.2691 - auc: 0.8566 - prc: 0.4986 - val_loss: 0.2265 - val_tp: 543.0000 - val_fp: 229.0000 - val_tn: 17803.0000 - val_fn: 1425.0000 - val_accuracy: 0.9173 - val_precision: 0.7034 - val_recall: 0.2759 - val_auc: 0.8640 - val_prc: 0.5109\n","Epoch 33/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2344 - tp: 4358.0000 - fp: 2073.0000 - tn: 141805.0000 - fn: 11764.0000 - accuracy: 0.9135 - precision: 0.6777 - recall: 0.2703 - auc: 0.8566 - prc: 0.5009 - val_loss: 0.2266 - val_tp: 568.0000 - val_fp: 240.0000 - val_tn: 17792.0000 - val_fn: 1400.0000 - val_accuracy: 0.9180 - val_precision: 0.7030 - val_recall: 0.2886 - val_auc: 0.8638 - val_prc: 0.5112\n","Epoch 34/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2344 - tp: 4364.0000 - fp: 2091.0000 - tn: 141787.0000 - fn: 11758.0000 - accuracy: 0.9134 - precision: 0.6761 - recall: 0.2707 - auc: 0.8569 - prc: 0.4999 - val_loss: 0.2271 - val_tp: 604.0000 - val_fp: 273.0000 - val_tn: 17759.0000 - val_fn: 1364.0000 - val_accuracy: 0.9182 - val_precision: 0.6887 - val_recall: 0.3069 - val_auc: 0.8642 - val_prc: 0.5114\n","Epoch 35/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2346 - tp: 4365.0000 - fp: 2111.0000 - tn: 141767.0000 - fn: 11757.0000 - accuracy: 0.9133 - precision: 0.6740 - recall: 0.2707 - auc: 0.8563 - prc: 0.5008 - val_loss: 0.2267 - val_tp: 572.0000 - val_fp: 248.0000 - val_tn: 17784.0000 - val_fn: 1396.0000 - val_accuracy: 0.9178 - val_precision: 0.6976 - val_recall: 0.2907 - val_auc: 0.8642 - val_prc: 0.5111\n","Epoch 36/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2345 - tp: 4342.0000 - fp: 2076.0000 - tn: 141802.0000 - fn: 11780.0000 - accuracy: 0.9134 - precision: 0.6765 - recall: 0.2693 - auc: 0.8567 - prc: 0.5001 - val_loss: 0.2267 - val_tp: 561.0000 - val_fp: 239.0000 - val_tn: 17793.0000 - val_fn: 1407.0000 - val_accuracy: 0.9177 - val_precision: 0.7013 - val_recall: 0.2851 - val_auc: 0.8638 - val_prc: 0.5105\n","Epoch 37/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2342 - tp: 4339.0000 - fp: 2085.0000 - tn: 141793.0000 - fn: 11783.0000 - accuracy: 0.9133 - precision: 0.6754 - recall: 0.2691 - auc: 0.8569 - prc: 0.5014 - val_loss: 0.2265 - val_tp: 552.0000 - val_fp: 232.0000 - val_tn: 17800.0000 - val_fn: 1416.0000 - val_accuracy: 0.9176 - val_precision: 0.7041 - val_recall: 0.2805 - val_auc: 0.8641 - val_prc: 0.5111\n","Epoch 38/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2347 - tp: 4376.0000 - fp: 2125.0000 - tn: 141753.0000 - fn: 11746.0000 - accuracy: 0.9133 - precision: 0.6731 - recall: 0.2714 - auc: 0.8564 - prc: 0.4999 - val_loss: 0.2265 - val_tp: 553.0000 - val_fp: 237.0000 - val_tn: 17795.0000 - val_fn: 1415.0000 - val_accuracy: 0.9174 - val_precision: 0.7000 - val_recall: 0.2810 - val_auc: 0.8643 - val_prc: 0.5117\n","Epoch 39/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2340 - tp: 4368.0000 - fp: 2085.0000 - tn: 141793.0000 - fn: 11754.0000 - accuracy: 0.9135 - precision: 0.6769 - recall: 0.2709 - auc: 0.8575 - prc: 0.5018 - val_loss: 0.2265 - val_tp: 538.0000 - val_fp: 225.0000 - val_tn: 17807.0000 - val_fn: 1430.0000 - val_accuracy: 0.9172 - val_precision: 0.7051 - val_recall: 0.2734 - val_auc: 0.8638 - val_prc: 0.5110\n","Epoch 40/100\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2344 - tp: 4374.0000 - fp: 2071.0000 - tn: 141807.0000 - fn: 11748.0000 - accuracy: 0.9136 - precision: 0.6787 - recall: 0.2713 - auc: 0.8569 - prc: 0.5007 - val_loss: 0.2269 - val_tp: 559.0000 - val_fp: 245.0000 - val_tn: 17787.0000 - val_fn: 1409.0000 - val_accuracy: 0.9173 - val_precision: 0.6953 - val_recall: 0.2840 - val_auc: 0.8637 - val_prc: 0.5108\n","Epoch 41/100\n","160/160 [==============================] - 1s 9ms/step - loss: 0.2343 - tp: 4396.0000 - fp: 2096.0000 - tn: 141782.0000 - fn: 11726.0000 - accuracy: 0.9136 - precision: 0.6771 - recall: 0.2727 - auc: 0.8568 - prc: 0.5005 - val_loss: 0.2267 - val_tp: 570.0000 - val_fp: 246.0000 - val_tn: 17786.0000 - val_fn: 1398.0000 - val_accuracy: 0.9178 - val_precision: 0.6985 - val_recall: 0.2896 - val_auc: 0.8640 - val_prc: 0.5111\n"]}]},{"cell_type":"code","source":["sub=pd.read_csv('/content/drive/MyDrive/Data Science Project - Team D/data/raw-data/sample_submission.csv')\n","sub.head()\n","\n","X_test = test.drop(['ID_code'], axis=1)\n","\n","test.head()\n","\n","y_pred = model.predict(X_test)\n","\n","sub[\"target\"] = y_pred\n","sub.describe()\n","\n","sub.to_csv('/content/drive/MyDrive/Data Science Project - Team D/submission/various_submissions/fe0_ann.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JwSLSiO0Z_eg","executionInfo":{"status":"ok","timestamp":1671806950826,"user_tz":-60,"elapsed":27160,"user":{"displayName":"Sven Schnydrig","userId":"07537939478620197257"}},"outputId":"a2b26fed-b7ee-4088-c46f-a271126559ce"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["6250/6250 [==============================] - 10s 2ms/step\n"]}]},{"cell_type":"markdown","source":["# Sources:\n","https://www.amazon.de/-/en/Aurélien-Géron/dp/1098125975/ref=sr_1_1?keywords=hands-on+machine+learning+with+scikit-learn%2C+keras%2C+and+tensorflow&qid=1671798944&sprefix=hands-on+mach%2Caps%2C167&sr=8-1"],"metadata":{"id":"bLsmz6d--z54"}}]}